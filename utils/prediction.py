import tensorflow.keras.backend as K
import tensorflow as tf


# ============================================================
# –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–æ—Ä—å–±—ã —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º
# ============================================================
def calculate_class_weights(class_percentages):
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∏—Ö —á–∞—Å—Ç–æ—Ç–µ
    
    Args:
        class_percentages: —Å–ª–æ–≤–∞—Ä—å {class_id: percentage}
        –ù–∞–ø—Ä–∏–º–µ—Ä: {0: 28.64, 1: 27.32, 2: 23.85, 3: 12.62, 4: 1.80, 5: 5.78}
    
    Returns:
        dict: —Å–ª–æ–≤–∞—Ä—å –≤–µ—Å–æ–≤ {class_id: weight}
    
    –§–æ—Ä–º—É–ª–∞: weight = total / (n_classes * class_percentage)
    –≠—Ç–æ –¥–∞–µ—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å —Ä–µ–¥–∫–∏–º –∫–ª–∞—Å—Å–∞–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, cars: 1.80%)
    """
    total = sum(class_percentages.values())
    class_weights = {}
    
    print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –∏–∑ EDA:")
    for class_id, pct in class_percentages.items():
        print(f"  –ö–ª–∞—Å—Å {class_id}: {pct}%")
    
    for class_id, pct in class_percentages.items():
        # –§–æ—Ä–º—É–ª–∞: weight = total / (n_classes * class_percentage)
        weight = total / (len(class_percentages) * pct)
        class_weights[class_id] = weight
    
    print("\n‚öñÔ∏è –†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤:")
    class_names = ['roads', 'buildings', 'low_veg', 'trees', 'cars', 'clutter']
    for class_id, weight in class_weights.items():
        class_name = class_names[class_id] if class_id < len(class_names) else f"class_{class_id}"
        print(f"  {class_name:12} (–∫–ª–∞—Å—Å {class_id}): {weight:.3f}")
    
    print(f"\nüéØ –ö–ª–∞—Å—Å 'cars' –ø–æ–ª—É—á–∏–ª –≤–µ—Å {class_weights[4]:.3f} (–≤ ~{class_weights[4]/class_weights[0]:.1f}x –±–æ–ª—å—à–µ —á–µ–º roads)")
    print("   –≠—Ç–æ –∑–∞—Å—Ç–∞–≤–∏—Ç –º–æ–¥–µ–ª—å —É–¥–µ–ª—è—Ç—å –±–æ–ª—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è —Ä–µ–¥–∫–æ–º—É –∫–ª–∞—Å—Å—É!")
    
    return class_weights


# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ EDA:
# roads: 28.64%, buildings: 27.32%, low_veg: 23.85%,
# trees: 12.62%, clutter: 5.78%, cars: 1.80%
CLASS_PERCENTAGES = {
    0: 28.64,  # roads
    1: 27.32,  # buildings
    2: 23.85,  # low_veg
    3: 12.62,  # trees
    4: 1.80,   # cars - –†–ï–î–ö–ò–ô –ö–õ–ê–°–°!
    5: 5.78    # clutter
}

# –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
class_weights = calculate_class_weights(CLASS_PERCENTAGES)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –ñ–∞–∫–∫–∞—Ä–∞ (IoU)
def jacard_coef(y_true, y_pred):
    """
    Jaccard coefficient (IoU) - –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    """
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –≤ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
    intersection = K.sum(y_true_f * y_pred_f)

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –ñ–∞–∫–∫–∞—Ä–∞
    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)

# Weighted Categorical Crossentropy Loss
def weighted_categorical_crossentropy(class_weights_dict):
    """
    –°–æ–∑–¥–∞–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω—É—é categorical crossentropy loss —Ñ—É–Ω–∫—Ü–∏—é
    –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –≤—Å—Ç—Ä–æ–µ–Ω—ã –≤ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞–º–∏
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å –≤ —Ç–µ–Ω–∑–æ—Ä (—è–≤–Ω–æ float32)
    weights = tf.constant([class_weights_dict[i] for i in range(len(class_weights_dict))], dtype=tf.float32)

    def loss(y_true, y_pred):
        # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ –∫ float32 –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ —Ç–∏–ø–æ–≤
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å–∞ –∫ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É
        weights_per_pixel = tf.reduce_sum(y_true * weights, axis=-1)

        # Categorical crossentropy —Å numerical stability
        epsilon = tf.constant(K.epsilon(), dtype=tf.float32)
        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)
        crossentropy = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å–∞
        weighted_crossentropy = crossentropy * weights_per_pixel

        return tf.reduce_mean(weighted_crossentropy)

    return loss

# –°–æ–∑–¥–∞–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é loss —Ñ—É–Ω–∫—Ü–∏—é —Å –Ω–∞—à–∏–º–∏ –≤–µ—Å–∞–º–∏
weighted_loss = weighted_categorical_crossentropy(class_weights)
