# üõ∞Ô∏è –í–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∑–¥–∞–Ω–∏–π –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö

–í–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∑–¥–∞–Ω–∏–π –∏ –æ–±—ä–µ–∫—Ç–æ–≤ –≥–æ—Ä–æ–¥—Å–∫–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (U-Net + ResNet34).

## üìã –û–ø–∏—Å–∞–Ω–∏–µ

–°–∏—Å—Ç–µ–º–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ø–∏–∫—Å–µ–ª—å–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–æ–≤ –Ω–∞ 6 –∫–ª–∞—Å—Å–æ–≤:
- üõ£Ô∏è **–î–æ—Ä–æ–≥–∏** (roads) ‚Äî –¥–æ—Ä–æ–∂–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ, –ø–∞—Ä–∫–æ–≤–∫–∏
- üè¢ **–ó–¥–∞–Ω–∏—è** (buildings) ‚Äî –∂–∏–ª—ã–µ –∏ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–µ –∑–¥–∞–Ω–∏—è
- üåø **–ù–∏–∑–∫–∞—è —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** (low vegetation) ‚Äî –≥–∞–∑–æ–Ω—ã, –∫—É—Å—Ç–∞—Ä–Ω–∏–∫–∏
- üå≥ **–î–µ—Ä–µ–≤—å—è** (trees) ‚Äî –¥–µ—Ä–µ–≤—å—è, –ª–µ—Å–Ω—ã–µ –Ω–∞—Å–∞–∂–¥–µ–Ω–∏—è
- üöó **–ê–≤—Ç–æ–º–æ–±–∏–ª–∏** (cars) ‚Äî —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞
- üî¥ **–ü—Ä–æ—á–µ–µ** (clutter) ‚Äî –ø—Ä–æ—á–∏–µ –æ–±—ä–µ–∫—Ç—ã

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** U-Net —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º —ç–Ω–∫–æ–¥–µ—Ä–æ–º ResNet34  
**–î–∞—Ç–∞—Å–µ—Ç:** Potsdam (2400 –ø–∞—Ç—á–µ–π 300√ó300 px)  
**–ö–∞—á–µ—Å—Ç–≤–æ:** IoU 71.56%, F1-Score 82.73%, Accuracy 87.22%

## üì∏ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
![–ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è](models/training_plots.png)

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
![–ü—Ä–∏–º–µ—Ä—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏](models/validation_results.png)

### –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
![Confusion Matrix](models/confusion_matrix.png)

## üöÄ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

**Backend:**
- FastAPI 0.95.0 ‚Äî REST API
- TensorFlow 2.10.0 ‚Äî –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏
- Segmentation Models ‚Äî –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- OpenCV ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- Uvicorn ‚Äî ASGI —Å–µ—Ä–≤–µ—Ä

**Frontend:**
- Streamlit 1.21.0 ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- Pillow ‚Äî —Ä–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
- Requests ‚Äî HTTP-–∫–ª–∏–µ–Ω—Ç

**ML:**
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: U-Net + ResNet34 encoder
- Framework: TensorFlow/Keras
- Transfer Learning: ImageNet weights
- –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è: Dropout 30%, L2 weight decay
- Loss: Weighted Categorical Crossentropy

## üì¶ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ
- Python 3.12
- 8 –ì–ë RAM
- 10 –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
- Windows 10/11, Linux (Ubuntu 20.04+), macOS 11+

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ
- Python 3.12
- 16 –ì–ë RAM
- NVIDIA GPU —Å 6+ –ì–ë VRAM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è)
- CUDA 11.2+ –∏ cuDNN 8.1+ (–¥–ª—è GPU)

## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```bash
git clone <repository-url>
cd segmentation-buildings
```

### 2. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è

**Windows:**
```cmd
python -m venv venv
venv\Scripts\activate
```

**Linux/macOS:**
```bash
python3.10 -m venv venv
source venv/bin/activate
```

### 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. –†–∞–∑–º–µ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `models/`:

```
models/
‚îî‚îÄ‚îÄ best_segmentation_model.h5  (~93 –ú–ë)
```

### 5. –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

**–¢–µ—Ä–º–∏–Ω–∞–ª 1 ‚Äî Backend (FastAPI):**
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

**–¢–µ—Ä–º–∏–Ω–∞–ª 2 ‚Äî Frontend (Streamlit):**
```bash
streamlit run app.py --server.port 8501
```

### 6. –û—Ç–∫—Ä—ã—Ç–∏–µ –≤ –±—Ä–∞—É–∑–µ—Ä–µ

- **Frontend:** http://localhost:8501
- **API Docs:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
segmentation-buildings/
‚îú‚îÄ‚îÄ app.py                      # Frontend (Streamlit)
‚îú‚îÄ‚îÄ main.py                     # Backend API (FastAPI)
‚îú‚îÄ‚îÄ config.py                   # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ requirements.txt            # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îú‚îÄ‚îÄ models/                     # –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ best_segmentation_model.h5
‚îÇ   ‚îú‚îÄ‚îÄ training_history.csv
‚îÇ   ‚îú‚îÄ‚îÄ training_plots.png
‚îÇ   ‚îú‚îÄ‚îÄ validation_results.png
‚îÇ   ‚îî‚îÄ‚îÄ confusion_matrix.png
‚îú‚îÄ‚îÄ utils/                      # –£—Ç–∏–ª–∏—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ image_processing.py     # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py         # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã
‚îÇ   ‚îú‚îÄ‚îÄ prediction.py           # –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –º–µ—Ç—Ä–∏–∫–∏
‚îÇ   ‚îî‚îÄ‚îÄ window.py               # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚îú‚îÄ‚îÄ data/                       # –î–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
‚îÇ   ‚îî‚îÄ‚îÄ patches/
‚îÇ       ‚îú‚îÄ‚îÄ Images/
‚îÇ       ‚îî‚îÄ‚îÄ Labels/
‚îî‚îÄ‚îÄ notebooks/                  # Jupyter notebooks
    ‚îî‚îÄ‚îÄ segmentation_buildings.ipynb
```

## üîå API –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

```bash
GET /
```

**–û—Ç–≤–µ—Ç:**
```json
{
  "—Å–æ–æ–±—â–µ–Ω–∏–µ": "API –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç"
}
```

### –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

```bash
POST /predict/
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `file` (required) ‚Äî –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (JPEG, PNG, TIFF)

**–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 4096√ó4096 –ø–∏–∫—Å–µ–ª–µ–π

**–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ (cURL):**
```bash
curl -X POST "http://localhost:8000/predict/" \
  -H "accept: image/png" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@aerial_image.jpg" \
  --output result_segmentation.png
```

**–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ (Python):**
```python
import requests
from PIL import Image
import io

with open('aerial_image.jpg', 'rb') as f:
    files = {'file': ('aerial_image.jpg', f, 'image/jpeg')}
    response = requests.post('http://localhost:8000/predict/', files=files)

if response.status_code == 200:
    result = Image.open(io.BytesIO(response.content))
    result.save('result_segmentation.png')
```

**–û—Ç–≤–µ—Ç:**
- Content-Type: `image/png`
- –†–∞–∑–º–µ—Ä: 256√ó256 –ø–∏–∫—Å–µ–ª–µ–π
- –§–æ—Ä–º–∞—Ç: PNG —Å —Ü–≤–µ—Ç–æ–≤–æ–π –º–∞—Å–∫–æ–π

**–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞:**
- –ë–µ–ª—ã–π `#FFFFFF` ‚Äî –¥–æ—Ä–æ–≥–∏
- –°–∏–Ω–∏–π `#0000FF` ‚Äî –∑–¥–∞–Ω–∏—è
- –ì–æ–ª—É–±–æ–π `#00FFFF` ‚Äî –Ω–∏–∑–∫–∞—è —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- –ó–µ–ª—ë–Ω—ã–π `#00FF00` ‚Äî –¥–µ—Ä–µ–≤—å—è
- –ñ—ë–ª—Ç—ã–π `#FFFF00` ‚Äî –∞–≤—Ç–æ–º–æ–±–∏–ª–∏
- –ö—Ä–∞—Å–Ω—ã–π `#FF0000` ‚Äî –ø—Ä–æ—á–µ–µ

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** U-Net —Å ResNet34 —ç–Ω–∫–æ–¥–µ—Ä–æ–º (ImageNet weights)

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 24.4 –º–ª–Ω
- –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: 93 –ú–ë
- –í—Ö–æ–¥–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ: 256√ó256√ó3
- –í—ã—Ö–æ–¥–Ω—ã–µ –∫–ª–∞—Å—Å—ã: 6

**–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ:**
- **IoU Score:** 71.56%
- **F1-Score:** 82.73%
- **Accuracy:** 87.22%
- **Jaccard Coefficient:** 70.05%

**–ö–∞—á–µ—Å—Ç–≤–æ –ø–æ –∫–ª–∞—Å—Å–∞–º (Accuracy):**
- Roads: 92%
- Buildings: 97% ‚≠ê
- Low vegetation: 86%
- Trees: 96%
- Cars: 99% ‚≠ê
- Clutter: 97%

**–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: ~250-450 –º—Å (GPU Tesla T4)
- –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: ~180 –∑–∞–ø—Ä–æ—Å–æ–≤/–º–∏–Ω—É—Ç—É (4 workers)


## üõ†Ô∏è –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–¥–∞

**Backend (main.py):**
- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
- –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏
- –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

**Frontend (app.py):**
- –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ (drag-and-drop)
- –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (download)

**–£—Ç–∏–ª–∏—Ç—ã (utils/):**
- `image_processing.py` ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞, –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è, —Ü–≤–µ—Ç–æ–≤–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
- `model_loader.py` ‚Äî –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
- `prediction.py` ‚Äî —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å, –º–µ—Ç—Ä–∏–∫–∏, –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
- `window.py` ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (sliding window)

### –ó–∞–ø—É—Å–∫ —Å –∞–≤—Ç–æ–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–æ–π

```bash
# Backend
uvicorn main:app --reload

# Frontend
streamlit run app.py
```

### –ó–∞–ø—É—Å–∫ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ

```bash
# Backend —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ workers
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4

# Frontend –≤ headless —Ä–µ–∂–∏–º–µ
streamlit run app.py --server.headless true
```

## üìù –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –≤ Google Colab (notebook: `notebooks/segmentation_buildings.ipynb`)

**–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- Dataset: Potsdam (2400 –ø–∞—Ç—á–µ–π, train/val 80/20)
- Augmentation: horizontal flip, vertical flip
- Batch size: 16
- Epochs: 30 (—Å Early Stopping)
- Optimizer: Adam (lr=5e-5, weight decay=1e-5)
- Loss: Weighted Categorical Crossentropy (–¥–ª—è –±–æ—Ä—å–±—ã —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤)
- Callbacks: ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

**–í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ (–¥–ª—è –±–æ—Ä—å–±—ã —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º):**
- Roads: 0.582
- Buildings: 0.610
- Low vegetation: 0.699
- Trees: 1.321
- **Cars: 9.260** (—Ä–µ–¥–∫–∏–π –∫–ª–∞—Å—Å, –≤–µ—Å —É–≤–µ–ª–∏—á–µ–Ω –≤ 15.9√ó)
- Clutter: 2.884

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ü—Ä–æ–≤–µ—Ä–∫–∞ API

```bash
# Health check
curl http://localhost:8000/

# –¢–µ—Å—Ç–æ–≤–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
curl -X POST "http://localhost:8000/predict/" \
  -F "file=@test_image.jpg" \
  --output test_result.png
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏

```python
from keras.models import load_model
from utils.prediction import jacard_coef, weighted_loss

model = load_model(
    'models/best_segmentation_model.h5',
    custom_objects={
        'jacard_coef': jacard_coef,
        'loss': weighted_loss
    }
)

print(model.summary())
```

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω –≤ —Ä–∞–º–∫–∞—Ö –∏—Ç–æ–≥–æ–≤–æ–π –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏–æ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã.

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [FastAPI –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://fastapi.tiangolo.com/)
- [Streamlit –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://docs.streamlit.io/)
- [Segmentation Models](https://github.com/qubvel/segmentation_models)
- [Potsdam Dataset](https://www.isprs.org/education/benchmarks/UrbanSemLab/)

**–°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞:** ‚úÖ –ì–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é  
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025

